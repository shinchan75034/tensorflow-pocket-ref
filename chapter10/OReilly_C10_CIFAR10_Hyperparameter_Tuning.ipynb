{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OReilly_C10_CIFAR10_Hyperparameter_Tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnT8RQGF7yNNcGJ2B92+0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinchan75034/tensorflow-pocket-ref/blob/main/chapter10/OReilly_C10_CIFAR10_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sloNQ67s-jeN",
        "outputId": "9dbf1c70-de25-4fd5-c90a-cf23f19b8413"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 15.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYegFb29-Se1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJcUMQnOfnF9"
      },
      "source": [
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCitkpUU-Z_0",
        "outputId": "ba534c69-dd5f-4083-d6aa-55b5d5c4fefa"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBvJyq48j6Zp",
        "outputId": "82a46933-f707-435e-aef8-aa64886ed19d"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRC5A5oNkHwi"
      },
      "source": [
        "# Plain text name in alphabetical order. https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "CLASS_NAMES = ['airplane', 'automobile', 'bird', 'cat', \n",
        "               'deer','dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJfzAFG7kMEm"
      },
      "source": [
        "validation_dataset = tf.data.Dataset.from_tensor_slices((test_images[:500], test_labels[:500]))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images[500:], test_labels[500:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5jPKkxEkO_s"
      },
      "source": [
        "# Create an instance of dataset from raw numpy images and labels.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjnRZrTjkTeR",
        "outputId": "ff811034-de99-45e8-ab07-0aebe907e4b1"
      },
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset#transformations_2\n",
        "train_dataset_size = len(list(train_dataset.as_numpy_iterator()))\n",
        "print('Training data sample size: ', train_dataset_size)\n",
        "\n",
        "validation_dataset_size = len(list(validation_dataset.as_numpy_iterator()))\n",
        "print('Validation data sample size: ', validation_dataset_size)\n",
        "\n",
        "test_dataset_size = len(list(test_dataset.as_numpy_iterator()))\n",
        "print('Test data sample size: ', test_dataset_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data sample size:  50000\n",
            "Validation data sample size:  500\n",
            "Test data sample size:  9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aelXu2mkkdXp"
      },
      "source": [
        "## Define a distribution strategy\n",
        "Create a `MirroredStrategy` object to handle distributed training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siE2_JaBkWYB",
        "outputId": "93f92d78-999a-4af6-a569-f0097821e2aa"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB6hxFwCkfqT",
        "outputId": "aa215130-e17f-48fc-c38e-a75ffc56fab3"
      },
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncEy9lgNkiMI"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0JYDprLkkrV"
      },
      "source": [
        "train_dataset = train_dataset.repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE).batch(validation_dataset_size)\n",
        "test_dataset = test_dataset.batch(test_dataset_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9LsFdm-km78"
      },
      "source": [
        "STEPS_PER_EPOCH = train_dataset_size // BATCH_SIZE_PER_REPLICA\n",
        "VALIDATION_STEPS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqxCig1FlqVE"
      },
      "source": [
        "\n",
        "def build_model(hp):\n",
        "  model = tf.keras.Sequential()\n",
        "  # Node count for next layer as hyperparameter\n",
        "  hp_node_count = hp.Int('units', min_value=16, max_value=32, step=8)\n",
        "  model.add(tf.keras.layers.Conv2D(filters = hp_node_count, \n",
        "                                   kernel_size=(3, 3), \n",
        "                                   activation='relu', \n",
        "                                   name = 'conv_1',\n",
        "                                   kernel_initializer='glorot_uniform', \n",
        "                                   padding='same', input_shape = (32,32,3)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Flatten(name = 'flat_1'))\n",
        "  # Activation function for next layer as hyperparameter\n",
        "  hp_AF = hp.Choice('dense_activation', values = ['relu', 'tanh'])\n",
        "  model.add(tf.keras.layers.Dense(256, activation=hp_AF, \n",
        "                                  kernel_initializer='glorot_uniform', \n",
        "                                  name = 'dense_1'))\n",
        "  model.add(tf.keras.layers.Dense(10, activation='softmax', \n",
        "                                  name = 'custom_class'))\n",
        "\n",
        "  \n",
        "  model.build([None, 32, 32, 3])\n",
        "  # Compile model with optimizer \n",
        "  # Learning rate as hyperparameter\n",
        "  hp_LR = hp.Float('learning_rate', 1e-2, 1e-4)\n",
        "  \n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=hp_LR),\n",
        "      metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJh67gbEko_T"
      },
      "source": [
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "febib-xqtOp6"
      },
      "source": [
        "!ls -lrt ./my_dir/intro_to_kt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsfM031Fp0GO"
      },
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5esVKF9auYM"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "ts = time.time()\n",
        "print(ts) # finish epoch time in second \n",
        "datetime_time = datetime.datetime.fromtimestamp(ts)\n",
        "print(datetime_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCntSPNbrLDh"
      },
      "source": [
        "tuner.search(train_dataset, \n",
        "             steps_per_epoch = STEPS_PER_EPOCH,\n",
        "             validation_data = validation_dataset,\n",
        "             validation_steps = VALIDATION_STEPS,\n",
        "             epochs = 15,\n",
        "             callbacks = [early_stop]\n",
        "             )\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in conv_1\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')} and the optimal activation for dense_1 layer\n",
        "is {best_hps.get('dense_activation')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a27h6azXs1Uj"
      },
      "source": [
        "ts = time.time()\n",
        "print(ts) # finish epoch time in second \n",
        "datetime_time = datetime.datetime.fromtimestamp(ts)\n",
        "print(datetime_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fJU2HrZtmVm"
      },
      "source": [
        "#Started in 5:28 pm CDT. 1617402511"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO9RoOUxvfgB"
      },
      "source": [
        "1617403117 - 1617402511\n",
        "# 10 minutes running time."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpRHTNS9viav"
      },
      "source": [
        "best_hps.get('units')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1otzROItv2Wc"
      },
      "source": [
        "best_hps.get('learning_rate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78OapOudv7eq"
      },
      "source": [
        "best_hps.get('dense_activation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq-aGFWyexqi"
      },
      "source": [
        "## Launch full training with best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7dY-Y5Pv9wN"
      },
      "source": [
        "best_hp_model = tuner.hypermodel.build(best_hps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmLjw8NfZRn"
      },
      "source": [
        "MODEL_NAME = 'myCIFAR10-{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "print(MODEL_NAME)\n",
        "checkpoint_dir = './' + MODEL_NAME\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt-{epoch}\")\n",
        "print(checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx85JT6sfU_F"
      },
      "source": [
        "myCheckPoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_weights_only = True,\n",
        "    save_best_only = True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxPFeNIZfBl4"
      },
      "source": [
        "best_hp_model.fit(train_dataset, \n",
        "             steps_per_epoch = STEPS_PER_EPOCH,\n",
        "             validation_data = validation_dataset,\n",
        "             validation_steps = VALIDATION_STEPS,\n",
        "             epochs = 15,\n",
        "             callbacks = [early_stop, myCheckPoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx1UtBQUfvp3"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ8zc-HfqYhn"
      },
      "source": [
        "best_hp_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btkmxJSJqgF_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}